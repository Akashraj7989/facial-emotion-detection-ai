{% extends "base.html" %}
{% block title %}Live Emotion Detection{% endblock %}
{% block content %}

<div class="container text-center mt-4">
  <div class="card p-4 shadow-lg">
    <h3 class="mb-3">ðŸŽ¥ Live Facial Emotion Detection</h3>

    <div class="position-relative">
      <video id="video" autoplay playsinline class="w-100 rounded" 
        style="max-width: 600px; border: 3px solid #667eea;"></video>
    </div>

    <div class="mt-3">
      <select id="cameraSelect" class="form-select mb-3"></select>
      <button id="captureBtn" class="btn btn-primary px-4">Analyze Emotion</button>
    </div>

    <div id="result" class="mt-4 emotion-result d-none">
      <h5>Detected Emotion: <span id="emotion-text" class="fw-bold"></span></h5>
      <div class="progress mt-3">
        <div id="confidence-bar" class="progress-bar" role="progressbar" style="width: 0%"></div>
      </div>
    </div>
  </div>
</div>

<script>
  const video = document.getElementById('video');
  const captureBtn = document.getElementById('captureBtn');
  const resultDiv = document.getElementById('result');
  const emotionText = document.getElementById('emotion-text');
  const confidenceBar = document.getElementById('confidence-bar');
  const cameraSelect = document.getElementById('cameraSelect');
  let currentStream = null;

  // âœ… Load and list available cameras (front/rear)
  async function loadCameras() {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const videoDevices = devices.filter(device => device.kind === "videoinput");

      cameraSelect.innerHTML = "";
      videoDevices.forEach((device, index) => {
        const option = document.createElement("option");
        option.value = device.deviceId;
        option.text = device.label || `Camera ${index + 1}`;
        cameraSelect.appendChild(option);
      });

      // Default to rear camera if on mobile
      let backCam = videoDevices.find(d => d.label.toLowerCase().includes("back"));
      startCamera(backCam ? backCam.deviceId : videoDevices[0].deviceId);
    } catch (err) {
      alert("Camera access denied or unavailable: " + err.message);
    }
  }

  // âœ… Start the selected camera
  async function startCamera(deviceId) {
    if (currentStream) {
      currentStream.getTracks().forEach(track => track.stop());
    }
    try {
      const constraints = {
        audio: false,
        video: deviceId ? { deviceId: { exact: deviceId } } : { facingMode: "user" },
      };
      currentStream = await navigator.mediaDevices.getUserMedia(constraints);
      video.srcObject = currentStream;
    } catch (err) {
      console.error("Camera start error:", err);
      alert("Unable to access selected camera.");
    }
  }

  // âœ… Switch camera when user selects another
  cameraSelect.addEventListener("change", e => startCamera(e.target.value));

  // âœ… Capture frame and send to backend
  captureBtn.addEventListener("click", async () => {
    const canvas = document.createElement("canvas");
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const context = canvas.getContext("2d");
    context.drawImage(video, 0, 0, canvas.width, canvas.height);

    const blob = await new Promise(resolve => canvas.toBlob(resolve, "image/jpeg"));
    const formData = new FormData();
    formData.append("image", blob, "frame.jpg");

    try {
      const response = await fetch("/analyze_frame", {
        method: "POST",
        body: formData
      });

      const data = await response.json();
      resultDiv.classList.remove("d-none");
      emotionText.innerText = data.emotion;
      confidenceBar.style.width = (data.confidence || 90) + "%";
    } catch (error) {
      console.error("Error detecting emotion:", error);
      emotionText.innerText = "Error";
    }
  });

  loadCameras();
</script>

{% endblock %}
